# -*- coding: utf-8 -*-
"""BreastCancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PN4pTGm5vGUfqFy7FiS2a3Aat2u4a7E0
"""

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Load the Data
from google.colab import files
uploaded = files.upload()
df = pd.read_csv("data.csv")
df.head(7)

#Count the no. of rows and columns of the matrix
df.shape

#counting the rows with no value
df.isna().sum()

#Drop the column with all missing values
df = df.dropna(axis = 1)

df.shape

#get a count of the patients with diagnosis, Malignant M or benign b
df['diagnosis'].value_counts()

df.dtypes

#Encoding the catagorical Data
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:, 1] = labelencoder_Y.fit_transform(df.iloc[:, 1].values)

#Create a pair plot
sns.pairplot(df.iloc[:, 1:5], hue = )



#print first 5 rows of the new data
df.head(5)

#Get the correlation of the columns
df.iloc[:, 1:12].corr()

#visualize the correlation
plt.figure(figsize = (10,10))
sns.heatmap(df.iloc[:, 1:12].corr(), annot = True, fmt = '.0%')

#split the data set into independent x and dependent Y
X = df.iloc[:, 2:31].values
Y = df.iloc[:, 1].values

#Splitting the dataset into Training and Testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.25, random_state = 0)

#Scaling the data
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

#Create a function for the models
def models(X_train, Y_train):
  #Logistic Regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state = 0)
  log.fit(X_train, Y_train)

  #Decision Tree 
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
  tree.fit(X_train, Y_train)

  #Random Forest
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
  forest.fit(X_train, Y_train)

  #print the model accuracy on the training data
  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train) )
  print('[1]Decision Tree Regression Training Accuracy:', tree.score(X_train, Y_train) )
  print('[2]Random Forest Regression Training Accuracy:', forest.score(X_train, Y_train) )
 
  return log, tree, forest

#Getting all of the variables
model = models(X_train, Y_train)

#test model accuracy on test data on confusion matrix
from sklearn.metrics import confusion_matrix
for i in range(len(model)): 
  print('Model',i) 
  cm = confusion_matrix(Y_test, model[i].predict(X_test))
  TP = cm[0][0]
  TN = cm[1][1]
  FP = cm[0][1]
  FN = cm[1][0]
  print(cm)
  print('Testing accuracy = ', (TP + TN) / (TP+TN+FP+FN)) 
  print()

#show another way to get the metrics 
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score


for i in range(len(model)):
  print('model',i)
  print(classification_report(Y_test, model[i].predict(X_test)))
  print(accuracy_score(Y_test, model[i].predict(X_test)))
  print()

#Print the prediction of Logistic Regression
pred = model[0].predict(X_test)
print(pred)
print()
print(Y_test)